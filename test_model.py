#!/usr/bin/env python3
"""
Quick test script for your trained multimodal model.
"""

import sys
import torch
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

def test_model():
    """Test the trained model with sample images."""
    
    print("ğŸ¤– Testing Qwen-CLIP Multimodal Model")
    print("=" * 50)
    
    try:
        # Import required modules
        from models import MultimodalLLM
        from inference import MultimodalInferencePipeline
        from transformers import Qwen2Tokenizer, CLIPImageProcessor
        
        print("âœ… Modules imported successfully")
        
        # Load tokenizer and image processor
        print("ğŸ”„ Loading tokenizer and image processor...")
        tokenizer = Qwen2Tokenizer.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
        image_processor = CLIPImageProcessor.from_pretrained("openai/clip-vit-base-patch32")
        
        # Add special tokens
        special_tokens = ["<image>", "<|im_start|>", "<|im_end|>"]
        tokenizer.add_special_tokens({"additional_special_tokens": special_tokens})
        
        print("âœ… Tokenizer and image processor loaded")
        
        # Load your trained model
        model_path = "outputs/coco_pretraining/best_model"
        print(f"ğŸ”„ Loading model from {model_path}...")
        
        model = MultimodalLLM.from_pretrained(model_path)
        pipeline = MultimodalInferencePipeline(model, tokenizer, image_processor)
        
        print("âœ… Model loaded successfully!")
        
        # Test with sample images
        test_images = [
            "test_data/images/test_image_1.jpg",
            "test_data/images/test_image_2.jpg"
        ]
        
        test_prompts = [
            "Describe this image in detail.",
            "What do you see in this picture?",
            "What is the main subject of this image?",
            "What colors are prominent in this image?",
            "What is happening in this scene?"
        ]
        
        print("\n" + "=" * 50)
        print("ğŸ–¼ï¸  TESTING WITH SAMPLE IMAGES")
        print("=" * 50)
        
        for i, image_path in enumerate(test_images, 1):
            if Path(image_path).exists():
                print(f"\nğŸ“¸ Test Image {i}: {image_path}")
                print("-" * 30)
                
                for j, prompt in enumerate(test_prompts[:2], 1):  # Test 2 prompts per image
                    try:
                        print(f"ğŸ’­ Prompt {j}: {prompt}")
                        response = pipeline.chat(prompt, image=image_path)
                        print(f"ğŸ¤– Response: {response}")
                        print()
                    except Exception as e:
                        print(f"âŒ Error with prompt {j}: {e}")
                        print()
            else:
                print(f"âš ï¸  Image not found: {image_path}")
        
        print("=" * 50)
        print("ğŸ‰ Model testing completed!")
        print("âœ… Your multimodal AI is working!")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("ğŸ’¡ Make sure all dependencies are installed: pip install -r requirements.txt")
    except FileNotFoundError as e:
        print(f"âŒ File not found: {e}")
        print("ğŸ’¡ Make sure your model was trained and saved correctly")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        print("ğŸ’¡ Check if your model training completed successfully")

def test_model_components():
    """Test individual model components."""
    
    print("\nğŸ”§ COMPONENT TESTING")
    print("=" * 30)
    
    try:
        # Test model loading
        model_path = "outputs/coco_pretraining/best_model"
        if Path(model_path).exists():
            print("âœ… Model directory exists")
            
            # Check required files
            required_files = ["model.safetensors", "training_state.json"]
            for file in required_files:
                file_path = Path(model_path) / file
                if file_path.exists():
                    size = file_path.stat().st_size / (1024*1024)  # MB
                    print(f"âœ… {file} exists ({size:.1f} MB)")
                else:
                    print(f"âŒ {file} missing")
        else:
            print(f"âŒ Model directory not found: {model_path}")
            print("ğŸ’¡ Run: cp -r outputs/coco_pretraining/checkpoints/stage1_step_153530 outputs/coco_pretraining/best_model")
            
    except Exception as e:
        print(f"âŒ Component test error: {e}")

if __name__ == "__main__":
    # Test components first
    test_model_components()
    
    # Then test the full model
    test_model()